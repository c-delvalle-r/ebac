{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo 47 - Big Data 1\n",
    "\n",
    "## Spark\n",
    "Spark es una herramienta de apache para la gestión y manejo de Big Data. Es un framework de procesamiento de información que puede generar acciones rápidas sobre cojuntos de datos muy grandes. Tiene capacidades de procesamiento distribuido en varios servidores; ideal para tratamiento de datos de machine learning.\n",
    "\n",
    "La arquitectura esta diseñada para escalar plataformas. Tiene un **Driver** que es el que convierte en código del usuario en tareas, que son a su vez ejecutadas por los **Executors** que habitan en los *Work Nodes* y que pueden estar distribuidos en los distintos servers. Generalmente existe una capa de manejo de Clusters para que  los Workers se auto adapten a la demanda del sistema. Esta capa puede ser Hadoop Yarn, Kubernetes, Docker Swarm, etc.\n",
    "\n",
    "### ¿Por qué Spark?\n",
    "1. Velocidad - Tiene un data-engine en memoria que puede reducir mucho su tiempo de ejecución de hasta 10x en tareas complejas respecto a su tecnología más parecida\n",
    "2. Spark API Amigable - La facilidad de llamar a la API de Spark lo hace muy atractivo. La implementación de la API esconde mucho del a complejidad de configurar y ejecutar un sistema tan complejo\n",
    "\n",
    "### Conceptos importantes Spark\n",
    "1. RDD (Resilient Distributed Dataset) Una abstracción para una colección de objetos que puede estar distribbuida en un cluster de servers. Pueden ser archivos de texto, bases de datos SQL, buckets S3, etc. El API de Spark es´ta construido sobre este concepto, donde se pueden hacer operaciones de unir data sets, filtrar, samplear datos, agregarlos, etc.\n",
    "2. Spark SQL - Originalmente llamdo Shark. Es la interfaz más conocida para tratar datos en Spark. Se usa el concepto de dataframe, implementación de SQL compliant con todos los estándares.\n",
    "\n",
    "### Otras librerias de Spark\n",
    "- Mllib - Framework para pipelines de Machine Learning - K-means, random forests, clasificación, regresión, etc.\n",
    "- GraphX - Procesamiento de estructura de imágenes Big Data. Se traducen los gráficos a dataframes, además de usar Catalyst\n",
    "- Streaming - Procesamiento de información en tiempo real. Se divide la información en \"micro-batches\" orquestados por la API de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n"
     ]
    }
   ],
   "source": [
    "# Librerias a importar\n",
    "import sys\n",
    "from random import random\n",
    "from operator import add\n",
    "import os\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark \n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .master(\"local\")\\\n",
    "            .appName(\"PythonPi\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of stack overflow forum\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']= \"notebook\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "\n",
    "import os\n",
    "import sys\n",
    "spark_path = \"C:\\Spark\\spark-3.5.1-bin-hadoop3\" # spark installed folder\n",
    "os.environ['SPARK_HOME'] = spark_path\n",
    "sys.path.insert(0, spark_path + \"/bin\")\n",
    "sys.path.insert(0, spark_path + \"/python/pyspark/\")\n",
    "sys.path.insert(0, spark_path + \"/python/lib/pyspark.zip\")\n",
    "sys.path.insert(0, spark_path + \"/python/lib/py4j-0.10.9.7-src.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 3.141200\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo Simple \n",
    "partitions = 4\n",
    "n = 100000 * partitions\n",
    "\n",
    "def f(_):\n",
    "    x = random()*2 - 1\n",
    "    y = random()*2 - 1\n",
    "    return 1 if x**2 + y**2 <= 1 else 0\n",
    "\n",
    "count = spark.sparkContext.parallelize(range(1, n+1), partitions).map(f).reduce(add)\n",
    "print('Pi is roughly %f' % (4.0 * count / n))\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones básicas de Spark\n",
    "- Lectura de Archivos\n",
    "- Análisis inicial de datos\n",
    "    - Crear sesión de Spark\n",
    "    - Generar un Schema y llenarlo de datos de un CSV\n",
    "    - Contar el número de filas, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar sesión de Spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Generar sesión\n",
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .appName(\"LecturaArchivoCSV\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivo de videojuegos\n",
    "path_archivo = \"D:/DataAnalysis_EBAC/ebac/Python/Modulo19/vgsales.csv\"\n",
    "df = spark.read.csv(path_archivo, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nota como es un dataframe de Spark, no pandas\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------+----+------------+---------+--------+--------+--------+-----------+------------+\n",
      "|Rank|                Name|Platform|Year|       Genre|Publisher|NA_Sales|EU_Sales|JP_Sales|Other_Sales|Global_Sales|\n",
      "+----+--------------------+--------+----+------------+---------+--------+--------+--------+-----------+------------+\n",
      "|   1|          Wii Sports|     Wii|2006|      Sports| Nintendo|   41.49|   29.02|    3.77|       8.46|       82.74|\n",
      "|   2|   Super Mario Bros.|     NES|1985|    Platform| Nintendo|   29.08|    3.58|    6.81|       0.77|       40.24|\n",
      "|   3|      Mario Kart Wii|     Wii|2008|      Racing| Nintendo|   15.85|   12.88|    3.79|       3.31|       35.82|\n",
      "|   4|   Wii Sports Resort|     Wii|2009|      Sports| Nintendo|   15.75|   11.01|    3.28|       2.96|          33|\n",
      "|   5|Pokemon Red/Pokem...|      GB|1996|Role-Playing| Nintendo|   11.27|    8.89|   10.22|          1|       31.37|\n",
      "|   6|              Tetris|      GB|1989|      Puzzle| Nintendo|    23.2|    2.26|    4.22|       0.58|       30.26|\n",
      "|   7|New Super Mario B...|      DS|2006|    Platform| Nintendo|   11.38|    9.23|     6.5|        2.9|       30.01|\n",
      "|   8|            Wii Play|     Wii|2006|        Misc| Nintendo|   14.03|     9.2|    2.93|       2.85|       29.02|\n",
      "|   9|New Super Mario B...|     Wii|2009|    Platform| Nintendo|   14.59|    7.06|     4.7|       2.26|       28.62|\n",
      "|  10|           Duck Hunt|     NES|1984|     Shooter| Nintendo|   26.93|    0.63|    0.28|       0.47|       28.31|\n",
      "+----+--------------------+--------+----+------------+---------+--------+--------+--------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rank', 'string'),\n",
       " ('Name', 'string'),\n",
       " ('Platform', 'string'),\n",
       " ('Year', 'string'),\n",
       " ('Genre', 'string'),\n",
       " ('Publisher', 'string'),\n",
       " ('NA_Sales', 'string'),\n",
       " ('EU_Sales', 'string'),\n",
       " ('JP_Sales', 'string'),\n",
       " ('Other_Sales', 'string'),\n",
       " ('Global_Sales', 'string')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Typos de datos\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rank', 'string'),\n",
       " ('Name', 'string'),\n",
       " ('Platform', 'string'),\n",
       " ('Year', 'string'),\n",
       " ('Genre', 'string'),\n",
       " ('Publisher', 'string'),\n",
       " ('NA_Sales', 'float'),\n",
       " ('EU_Sales', 'float'),\n",
       " ('JP_Sales', 'float'),\n",
       " ('Other_Sales', 'float'),\n",
       " ('Global_Sales', 'float')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cambiar números de string a float\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "df = df.withColumn('NA_Sales', df.NA_Sales.cast(FloatType()))\n",
    "df = df.withColumn('EU_Sales', df.EU_Sales.cast(FloatType()))\n",
    "df = df.withColumn('JP_Sales', df.JP_Sales.cast(FloatType()))\n",
    "df = df.withColumn('Other_Sales', df.Other_Sales.cast(FloatType()))\n",
    "df = df.withColumn('Global_Sales', df.Global_Sales.cast(FloatType()))\n",
    "\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Rank: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Platform: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Genre: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- NA_Sales: float (nullable = true)\n",
      " |-- EU_Sales: float (nullable = true)\n",
      " |-- JP_Sales: float (nullable = true)\n",
      " |-- Other_Sales: float (nullable = true)\n",
      " |-- Global_Sales: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprime la información de columnas de una manera jerárquica\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+--------+----+--------+------------+--------+--------+--------+-----------+------------+\n",
      "|Rank|           Name|Platform|Year|   Genre|   Publisher|NA_Sales|EU_Sales|JP_Sales|Other_Sales|Global_Sales|\n",
      "+----+---------------+--------+----+--------+------------+--------+--------+--------+-----------+------------+\n",
      "| 545|Missile Command|    2600|1980| Shooter|       Atari|    2.56|    0.17|     0.0|       0.03|        2.76|\n",
      "|1431|      Centipede|    2600|1981| Shooter|       Atari|    1.26|    0.08|     0.0|       0.01|        1.36|\n",
      "| 608| Space Invaders|    2600| N/A| Shooter|       Atari|    2.36|    0.14|     0.0|       0.03|        2.53|\n",
      "| 240|       Pitfall!|    2600|1981|Platform|  Activision|    4.21|    0.24|     0.0|       0.05|         4.5|\n",
      "| 736|        Frogger|    2600|1981|  Action|Parker Bros.|    2.06|    0.12|     0.0|       0.02|         2.2|\n",
      "|1108|    Ms. Pac-Man|    2600|1981|  Puzzle|       Atari|    1.54|     0.1|     0.0|       0.02|        1.65|\n",
      "|1117|        Dig Dug|    2600|1982|  Puzzle|       Atari|    1.52|     0.1|     0.0|       0.02|        1.64|\n",
      "|  90|        Pac-Man|    2600|1982|  Puzzle|       Atari|    7.28|    0.45|     0.0|       0.08|        7.81|\n",
      "|1155|     River Raid|    2600|1981| Shooter|  Activision|    1.49|    0.09|     0.0|       0.02|         1.6|\n",
      "| 768|   Demon Attack|    2600|1981| Shooter|      Imagic|    1.99|    0.12|     0.0|       0.02|        2.13|\n",
      "+----+---------------+--------+----+--------+------------+--------+--------+--------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordenamiento de Resuldados con .sort()\n",
    "import pyspark.sql.functions as F1\n",
    "\n",
    "# Se ordena por una columna\n",
    "df.sort(F1.col(\"Platform\")).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16598"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------+----+---------+-----------+--------+--------+--------+-----------+------------+\n",
      "|Rank|                Name|Platform|Year|    Genre|  Publisher|NA_Sales|EU_Sales|JP_Sales|Other_Sales|Global_Sales|\n",
      "+----+--------------------+--------+----+---------+-----------+--------+--------+--------+-----------+------------+\n",
      "|4380|Maze Craze: A Gam...|    2600| N/A|   Action|      Atari|    0.42|    0.02|     0.0|        0.0|        0.45|\n",
      "|4471|      Super Breakout|    2600| N/A|   Puzzle|      Atari|    0.41|    0.03|     0.0|        0.0|        0.44|\n",
      "|5063|             Hangman|    2600| N/A|   Puzzle|      Atari|    0.35|    0.02|     0.0|        0.0|        0.38|\n",
      "|1515|           Adventure|    2600| N/A|Adventure|      Atari|    1.21|    0.08|     0.0|       0.01|         1.3|\n",
      "|5659|            Dragster|    2600| N/A|   Racing| Activision|     0.3|    0.02|     0.0|        0.0|        0.32|\n",
      "|2115|      Air-Sea Battle|    2600| N/A|  Shooter|      Atari|    0.91|    0.06|     0.0|       0.01|        0.98|\n",
      "|5800|        Slot Machine|    2600| N/A|   Action|      Atari|    0.29|    0.02|     0.0|        0.0|        0.31|\n",
      "|4153|              Karate|    2600| N/A| Fighting|Ultravision|    0.44|    0.03|     0.0|        0.0|        0.47|\n",
      "|6285|            Indy 500|    2600| N/A|   Racing|      Atari|    0.26|    0.01|     0.0|        0.0|        0.27|\n",
      "| 608|      Space Invaders|    2600| N/A|  Shooter|      Atari|    2.36|    0.14|     0.0|       0.03|        2.53|\n",
      "+----+--------------------+--------+----+---------+-----------+--------+--------+--------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordenar por dos columnas\n",
    "df.sort(F1.col(\"Platform\"), F1.col('Year').desc()).show(10)\n",
    "\n",
    "# Nota como no se usan corchetes, solamente se listan las columnas por las que se quiere ordenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+--------+----+--------+----------+--------+--------+--------+-----------+------------+\n",
      "|Rank|           Name|Platform|Year|   Genre| Publisher|NA_Sales|EU_Sales|JP_Sales|Other_Sales|Global_Sales|\n",
      "+----+---------------+--------+----+--------+----------+--------+--------+--------+-----------+------------+\n",
      "| 259|      Asteroids|    2600|1980| Shooter|     Atari|     4.0|    0.26|     0.0|       0.05|        4.31|\n",
      "| 545|Missile Command|    2600|1980| Shooter|     Atari|    2.56|    0.17|     0.0|       0.03|        2.76|\n",
      "|1768|        Kaboom!|    2600|1980|    Misc|Activision|    1.07|    0.07|     0.0|       0.01|        1.15|\n",
      "|1971|       Defender|    2600|1980|    Misc|     Atari|    0.99|    0.05|     0.0|       0.01|        1.05|\n",
      "|2671|         Boxing|    2600|1980|Fighting|Activision|    0.72|    0.04|     0.0|       0.01|        0.77|\n",
      "|4027|     Ice Hockey|    2600|1980|  Sports|Activision|    0.46|    0.03|     0.0|       0.01|        0.49|\n",
      "|5368|        Freeway|    2600|1980|  Action|Activision|    0.32|    0.02|     0.0|        0.0|        0.34|\n",
      "|6319|         Bridge|    2600|1980|    Misc|Activision|    0.25|    0.02|     0.0|        0.0|        0.27|\n",
      "|6898|       Checkers|    2600|1980|    Misc|     Atari|    0.22|    0.01|     0.0|        0.0|        0.24|\n",
      "|1108|    Ms. Pac-Man|    2600|1981|  Puzzle|     Atari|    1.54|     0.1|     0.0|       0.02|        1.65|\n",
      "+----+---------------+--------+----+--------+----------+--------+--------+--------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Order by\n",
    "df.orderBy(\"Year\", 'Platform').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+------------------+\n",
      "|Platform|     Genre|   sum(Global_Sales)|     sum(NA_Sales)|\n",
      "+--------+----------+--------------------+------------------+\n",
      "|      PS|    Action|  127.05000039748847| 62.87999978289008|\n",
      "|     NES|    Puzzle|  20.999999906867743|  9.13999992236495|\n",
      "|    WiiU|  Strategy|  1.2400000132620335|0.5099999867379665|\n",
      "|     GBA|  Platform|   78.29999975115061| 45.81000040844083|\n",
      "|     Wii|  Fighting|  23.859999924898148|13.149999974295497|\n",
      "|    XOne|      Misc|   6.860000053420663| 4.439999930560589|\n",
      "|    XOne|  Fighting|  2.3100000210106373| 1.580000001937151|\n",
      "|     3DO|Simulation|0.019999999552965164|               0.0|\n",
      "|     PS4|    Action|   87.05999964103103|29.699999878183007|\n",
      "|      PS|    Puzzle|  12.080000067129731| 5.289999892935157|\n",
      "|      GB|    Puzzle|  47.470000356435776|29.350000709295273|\n",
      "|    X360|  Strategy|  10.130000134930015| 6.489999949932098|\n",
      "|      GC|    Racing|   21.88999987952411|14.929999867454171|\n",
      "|    XOne|    Action|  33.789999939501286|19.450000086799264|\n",
      "|     PS2|    Racing|  156.27999876625836| 75.71999965049326|\n",
      "|     PS2|  Platform|   72.50999970547855| 37.59999969229102|\n",
      "|      GC|    Puzzle|   4.699999975040555| 2.949999997392297|\n",
      "|      GC|    Sports|  25.490000020712614| 18.37000005505979|\n",
      "|    WiiU|    Puzzle|  1.3300000559538603|0.6600000038743019|\n",
      "|     GBA|Simulation|   5.910000009462237|3.6100000124424696|\n",
      "+--------+----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupación de resultados\n",
    "df.groupBy('Platform', \"Genre\").sum('Global_Sales', 'NA_Sales').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de SQL y tablas temporales dentro de PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+----+--------------------+--------+------------+\n",
      "|       Genre|                Name|Rank|           Publisher|NA_Sales|Global_Sales|\n",
      "+------------+--------------------+----+--------------------+--------+------------+\n",
      "|      Sports|          Wii Sports|   1|            Nintendo|   41.49|       82.74|\n",
      "|    Platform|   Super Mario Bros.|   2|            Nintendo|   29.08|       40.24|\n",
      "|      Racing|      Mario Kart Wii|   3|            Nintendo|   15.85|       35.82|\n",
      "|      Sports|   Wii Sports Resort|   4|            Nintendo|   15.75|        33.0|\n",
      "|Role-Playing|Pokemon Red/Pokem...|   5|            Nintendo|   11.27|       31.37|\n",
      "|      Puzzle|              Tetris|   6|            Nintendo|    23.2|       30.26|\n",
      "|    Platform|New Super Mario B...|   7|            Nintendo|   11.38|       30.01|\n",
      "|        Misc|            Wii Play|   8|            Nintendo|   14.03|       29.02|\n",
      "|    Platform|New Super Mario B...|   9|            Nintendo|   14.59|       28.62|\n",
      "|     Shooter|           Duck Hunt|  10|            Nintendo|   26.93|       28.31|\n",
      "|  Simulation|          Nintendogs|  11|            Nintendo|    9.07|       24.76|\n",
      "|      Racing|       Mario Kart DS|  12|            Nintendo|    9.81|       23.42|\n",
      "|Role-Playing|Pokemon Gold/Poke...|  13|            Nintendo|     9.0|        23.1|\n",
      "|      Sports|             Wii Fit|  14|            Nintendo|    8.94|       22.72|\n",
      "|      Sports|        Wii Fit Plus|  15|            Nintendo|    9.09|        22.0|\n",
      "|        Misc|  Kinect Adventures!|  16|Microsoft Game St...|   14.97|       21.82|\n",
      "|      Action|  Grand Theft Auto V|  17|Take-Two Interactive|    7.01|        21.4|\n",
      "|      Action|Grand Theft Auto:...|  18|Take-Two Interactive|    9.43|       20.81|\n",
      "|    Platform|   Super Mario World|  19|            Nintendo|   12.78|       20.61|\n",
      "|        Misc|Brain Age: Train ...|  20|            Nintendo|    4.75|       20.22|\n",
      "+------------+--------------------+----+--------------------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear tabla temporal\n",
    "df.createOrReplaceTempView('VGSALES')\n",
    "\n",
    "# Comando SQL\n",
    "sql_str = 'select Genre, Name, Rank, Publisher, NA_Sales, Global_Sales from VGSALES limit 20'\n",
    "\n",
    "# Ejecutar SQL\n",
    "spark.sql(sql_str).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+---------------------------+---------------------------+\n",
      "| Genre|           Publisher|round(sum(Global_Sales), 2)|round(sum(Global_Sales), 2)|\n",
      "+------+--------------------+---------------------------+---------------------------+\n",
      "|Action|           mixi, Inc|                       0.86|                       0.86|\n",
      "|Action|     dramatic create|                       0.01|                       0.01|\n",
      "|Action|         Zushi Games|                       0.02|                       0.02|\n",
      "|Action|           Zoo Games|                       0.27|                       0.27|\n",
      "|Action|Zoo Digital Publi...|                       0.78|                       0.78|\n",
      "|Action|                Yeti|                       0.01|                       0.01|\n",
      "|Action|         Xseed Games|                       0.11|                       0.11|\n",
      "|Action|  Wizard Video Games|                       0.62|                       0.62|\n",
      "|Action|Warner Bros. Inte...|                     118.24|                     118.24|\n",
      "|Action|             Wanadoo|                        0.6|                        0.6|\n",
      "|Action|       Vivendi Games|                       12.6|                       12.6|\n",
      "|Action|  Virgin Interactive|                      20.35|                      20.35|\n",
      "|Action|       Vir2L Studios|                       0.16|                       0.16|\n",
      "|Action|               Views|                       0.02|                       0.02|\n",
      "|Action|        Video System|                       0.19|                       0.19|\n",
      "|Action|             Unknown|                       4.32|                       4.32|\n",
      "|Action|Universal Interac...|                       3.68|                       3.68|\n",
      "|Action|     Universal Gamex|                       0.63|                       0.63|\n",
      "|Action|      Ubisoft Annecy|                       3.38|                       3.38|\n",
      "|Action|             Ubisoft|                     142.94|                     142.94|\n",
      "+------+--------------------+---------------------------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceGlobalTempView('VGSALES')\n",
    "sql_str =  \"\"\"\n",
    "                select  Genre, \n",
    "                        Publisher,\n",
    "                        round(sum(Global_Sales),2),\n",
    "                        round(sum(Global_Sales),2) \n",
    "                from VGSALES \n",
    "                group by Genre, Publisher \n",
    "                order by Genre, Publisher desc\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql_str).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Parte 2  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------------+---------------------------+---------------------------+\n",
      "| Genre|                             Publisher|round(sum(Global_Sales), 2)|round(sum(Global_Sales), 2)|\n",
      "+------+--------------------------------------+---------------------------+---------------------------+\n",
      "|Action|                             mixi, Inc|                       0.86|                       0.86|\n",
      "|Action|                       dramatic create|                       0.01|                       0.01|\n",
      "|Action|                           Zushi Games|                       0.02|                       0.02|\n",
      "|Action|                             Zoo Games|                       0.27|                       0.27|\n",
      "|Action|                Zoo Digital Publishing|                       0.78|                       0.78|\n",
      "|Action|                                  Yeti|                       0.01|                       0.01|\n",
      "|Action|                           Xseed Games|                       0.11|                       0.11|\n",
      "|Action|                    Wizard Video Games|                       0.62|                       0.62|\n",
      "|Action|Warner Bros. Interactive Entertainment|                     118.24|                     118.24|\n",
      "|Action|                               Wanadoo|                        0.6|                        0.6|\n",
      "+------+--------------------------------------+---------------------------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceGlobalTempView('VGSALES')\n",
    "sql_str =  \"\"\"\n",
    "                select  Genre, \n",
    "                        Publisher,\n",
    "                        round(sum(Global_Sales),2),\n",
    "                        round(sum(Global_Sales),2) \n",
    "                from VGSALES \n",
    "                group by Genre, Publisher \n",
    "                order by Genre, Publisher desc\n",
    "\"\"\"\n",
    "\n",
    "# El 10 limita  mis resultados a 10 líneas, el 80 hace que el máximo de caracteres que se muestran en una celda se extienda hasta 80\n",
    "spark.sql(sql_str).show(10, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------\n",
      " Genre                       | Action                 \n",
      " Publisher                   | mixi, Inc              \n",
      " round(sum(Global_Sales), 2) | 0.86                   \n",
      " round(sum(Global_Sales), 2) | 0.86                   \n",
      "-RECORD 1---------------------------------------------\n",
      " Genre                       | Action                 \n",
      " Publisher                   | dramatic create        \n",
      " round(sum(Global_Sales), 2) | 0.01                   \n",
      " round(sum(Global_Sales), 2) | 0.01                   \n",
      "-RECORD 2---------------------------------------------\n",
      " Genre                       | Action                 \n",
      " Publisher                   | Zushi Games            \n",
      " round(sum(Global_Sales), 2) | 0.02                   \n",
      " round(sum(Global_Sales), 2) | 0.02                   \n",
      "-RECORD 3---------------------------------------------\n",
      " Genre                       | Action                 \n",
      " Publisher                   | Zoo Games              \n",
      " round(sum(Global_Sales), 2) | 0.27                   \n",
      " round(sum(Global_Sales), 2) | 0.27                   \n",
      "-RECORD 4---------------------------------------------\n",
      " Genre                       | Action                 \n",
      " Publisher                   | Zoo Digital Publishing \n",
      " round(sum(Global_Sales), 2) | 0.78                   \n",
      " round(sum(Global_Sales), 2) | 0.78                   \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceGlobalTempView('VGSALES')\n",
    "sql_str =  \"\"\"\n",
    "                select  Genre, \n",
    "                        Publisher,\n",
    "                        round(sum(Global_Sales),2),\n",
    "                        round(sum(Global_Sales),2) \n",
    "                from VGSALES \n",
    "                group by Genre, Publisher \n",
    "                order by Genre, Publisher desc\n",
    "\"\"\"\n",
    "\n",
    "# El True hace que el display sea en forma de tarjeta\n",
    "spark.sql(sql_str).show(5, 80, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particionamiento de Datos - partitionBy()\n",
    "Debido a la cantidad de información que podemos estar manejando en Spark, podemos dividir la data en pedazos más pequeños. La partición de datos consiste en dividir esa información en porciones más pequeñas pbasadas en algún criterio. Esto se usa para mejorar el perfomrmance en general. Para poder paralelizar el procesamiento.\n",
    "\n",
    "### Tres Tips:\n",
    "- No usar tamaños extremos - No particionar en datasets ni muy grandes ni muy pequeñas. Tratar de hacer que todas las particiones tengan aproximadamente el mismo tamaño. Se recomiendan tamaños de 256Mb a 1Gb por particion\n",
    "- No usar IDs para hacer la partición puesto que esto resultaría en muchas particiones de un registro\n",
    "- Usar columnas para particionar la data que van a ser usadas en sentencias groupBy\n",
    "\n",
    "### Tres tipos de particiones:\n",
    "- PartitionBy - Va a cambiar la estructura del folder uysando el criterio que se le especifique. \"Cortame por Género o por país o por plataforma\".  No controla cuántos archivos se generan debajo de cada folder. se puede combinar repartition + partitionBy\n",
    "- Repartition - Este método puede incrementar o reducir el # de particiones. Aqui se especifíca el número de particiones y los registros que hay en cada una se distribuyen al azar. \n",
    "- Coalesce - Reduce el número de particiones en un DataFrame. En vez de crear nuevas particiones mueve la data y la ajusta a las particiones existentes, por lo que solamente puede reducir el número de particiones. Es más barato computacionalmente.\n",
    "\n",
    "En términos prácticos se verá la creación de muchos archivos en los que cada método genera la data. Estos podrán ser varios volders, varios archiovs o una combinación de ambos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Rank: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Platform: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Genre: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- NA_Sales: float (nullable = true)\n",
      " |-- EU_Sales: float (nullable = true)\n",
      " |-- JP_Sales: float (nullable = true)\n",
      " |-- Other_Sales: float (nullable = true)\n",
      " |-- Global_Sales: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darse cuenta de que el campo por el que se hace partitionBy no aparece dentro de los datasets exportados\n",
    "df.write.option('header', True).partitionBy('Platform').mode('overwrite').csv('./partitions/platform')\n",
    "# df.write.option('header', True).partitionBy('Platform').mode('overwrite').format('csv').save('partitions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede hacer por multiples columnas\n",
    "df.write.option('header', True).partitionBy('Platform', 'Year').mode('overwrite').csv('./partitions/platform_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otro ejemplo, pero ahora controlando el numero de particiones\n",
    "df.write.option('header', True).option('maxRecordsPerFile', 10).partitionBy('Genre').mode('overwrite').csv('./partitions/yearMaxRows10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repartition\n",
    "df.repartition(20).write.mode(\"overwrite\").option('header', True).csv('./partitions/repartition') # Aqui pasamos el número de particiones que le queremos pasar (20)\n",
    "# Fíjate como en cada uno de los archivos, los indexes salen desordenados puesto que acomoda al azar en cada uno de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coalesce\n",
    "# A diferencia del repartition, coalesce sirve para disminuir el número de las particiones. Coalesce no aplica un full reshuffle a menos que sea necesario\n",
    "df.write.mode('overwrite').option('header', True).csv('./partitions/coalesce')  # not sure about this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
