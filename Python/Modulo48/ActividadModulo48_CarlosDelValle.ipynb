{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad Módulo 48: Big Data Parte 2\n",
    "Generar un archivo PDF que contenga las siguientes salidas:\n",
    "- Exportación de archivos desde Spark\n",
    "- Conexión desde Python al servicio Spark donde se instaló la información\n",
    "- Ejecución de comandos Python que traigan la misma salida de información obtenida en el ejercicio anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://127.0.0.1:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ActModulo48</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x21320fe7690>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conexión desde Python al servicio Spark donde se instaló la información\n",
    "\n",
    "# Generar sesión de spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .appName('ActModulo48')\\\n",
    "            .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- sqft_living: integer (nullable = true)\n",
      " |-- sqft_lot: integer (nullable = true)\n",
      " |-- floors: double (nullable = true)\n",
      " |-- waterfront: integer (nullable = true)\n",
      " |-- view: integer (nullable = true)\n",
      " |-- condition: integer (nullable = true)\n",
      " |-- grade: integer (nullable = true)\n",
      " |-- sqft_above: integer (nullable = true)\n",
      " |-- sqft_basement: integer (nullable = true)\n",
      " |-- yr_built: integer (nullable = true)\n",
      " |-- yr_renovated: integer (nullable = true)\n",
      " |-- zipcode: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- sqft_living15: integer (nullable = true)\n",
      " |-- sqft_lot15: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos de housing\n",
    "path_archivo = \"D:/DataAnalysis_EBAC/ebac/Python/Modulo44/kc_house_data.csv\"\n",
    "df = spark.read.csv(path_archivo, header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('zipcode').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportación de datos desde Spark - Hacer particiones (Por Genre)\n",
    "df.write.option('header', True).partitionBy('zipcode').mode('overwrite').csv('./partitions/byZipcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----------------+------------------+\n",
      "|zipcode|id_count|        avg_price|    sqft_living_m2|\n",
      "+-------+--------+-----------------+------------------+\n",
      "|  98103|     600|584919.2109634551|153.36215946843853|\n",
      "|  98038|     587|         366867.6|199.52274711864408|\n",
      "|  98115|     576|619900.5471698113|  170.498907890223|\n",
      "+-------+--------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejecución de comandos Python que traigan la misma salida de información obtenida en el ejercicio anterior\n",
    "# Ejecución de comandos SQL con la misma salida de información del ejercicio del Módulo 47\n",
    "\n",
    "# Para el zipcode con mayor número de casas, calcular el promedio de precio y tamaño en m2\n",
    "df.createOrReplaceTempView('KC_HOUSING')\n",
    "\n",
    "sql_str = \"\"\"\n",
    "            select  zipcode,\n",
    "                    count(distinct id) as id_count,\n",
    "                    avg(price) as avg_price,\n",
    "                    avg(sqft_living) * 0.0929 as sqft_living_m2\n",
    "            from KC_HOUSING\n",
    "            group by zipcode\n",
    "            order by count(distinct id) desc\n",
    "            limit 3     \n",
    "\"\"\"\n",
    "spark.sql(sql_str).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+------------------+\n",
      "|zipcode|bedrooms|bathrooms|         avg_price|\n",
      "+-------+--------+---------+------------------+\n",
      "|  98001|       0|      0.0|          139950.0|\n",
      "|  98001|       1|      1.0|          166000.0|\n",
      "|  98001|       1|      2.0|          171000.0|\n",
      "|  98001|       2|      1.0|197428.57142857142|\n",
      "|  98001|       2|      1.5|          350000.0|\n",
      "|  98001|       2|     1.75|          246112.5|\n",
      "|  98001|       2|      2.5|          214100.0|\n",
      "|  98001|       2|     2.75|          239475.0|\n",
      "|  98001|       3|     0.75|          363000.0|\n",
      "|  98001|       3|      1.0|205182.80952380953|\n",
      "|  98001|       3|      1.5|          224108.5|\n",
      "|  98001|       3|     1.75| 260531.0810810811|\n",
      "|  98001|       3|      2.0|256841.42857142858|\n",
      "|  98001|       3|     2.25|          265999.0|\n",
      "|  98001|       3|      2.5| 308581.8604651163|\n",
      "|  98001|       3|     2.75|          255000.0|\n",
      "|  98001|       3|      3.0|          309500.0|\n",
      "|  98001|       4|      1.0|          229790.0|\n",
      "|  98001|       4|      1.5|246406.85714285713|\n",
      "|  98001|       4|     1.75| 251114.2857142857|\n",
      "+-------+--------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupamiento en Spark, por zipcode, por número de habitaciones y baños, precio promedio\n",
    "\n",
    "df.createOrReplaceTempView('KC_HOUSING')\n",
    "\n",
    "sql_str = \"\"\"\n",
    "            select  zipcode,\n",
    "                    bedrooms,\n",
    "                    bathrooms,\n",
    "                    avg(price) as avg_price\n",
    "            from KC_HOUSING\n",
    "            group by zipcode, bedrooms, bathrooms\n",
    "            order by 1,2,3\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(sql_str).show(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
